{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d167ee0b",
   "metadata": {
    "papermill": {
     "duration": 0.007736,
     "end_time": "2023-12-20T15:05:44.982200",
     "exception": false,
     "start_time": "2023-12-20T15:05:44.974464",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10f9b8ba",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-12-20T15:05:44.997922Z",
     "iopub.status.busy": "2023-12-20T15:05:44.997567Z",
     "iopub.status.idle": "2023-12-20T15:05:49.792684Z",
     "shell.execute_reply": "2023-12-20T15:05:49.791473Z"
    },
    "papermill": {
     "duration": 4.806175,
     "end_time": "2023-12-20T15:05:49.795597",
     "exception": false,
     "start_time": "2023-12-20T15:05:44.989422",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/opt/conda/lib/python3.10/site-packages/dask/dataframe/_pyarrow_compat.py:23: UserWarning: You are using pyarrow version 11.0.0 which is known to be insecure. See https://www.cve.org/CVERecord?id=CVE-2023-47248 for further details. Please upgrade to pyarrow>=14.0.1 or install pyarrow-hotfix to patch your current version.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import gc  \n",
    "import os  \n",
    "import time  \n",
    "import warnings \n",
    "from itertools import combinations  \n",
    "from warnings import simplefilter \n",
    "import joblib  \n",
    "import lightgbm as lgb  \n",
    "import numpy as np  \n",
    "import pandas as pd  \n",
    "from sklearn.metrics import mean_absolute_error \n",
    "from sklearn.model_selection import KFold, TimeSeriesSplit  \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "simplefilter(action=\"ignore\", category=pd.errors.PerformanceWarning)\n",
    "is_offline = False \n",
    "is_train = True  \n",
    "is_infer = False \n",
    "max_lookback = np.nan \n",
    "split_day = 435\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3297b6a8",
   "metadata": {
    "papermill": {
     "duration": 0.008746,
     "end_time": "2023-12-20T15:05:49.813834",
     "exception": false,
     "start_time": "2023-12-20T15:05:49.805088",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Loading and Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61264aae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-20T15:05:49.834820Z",
     "iopub.status.busy": "2023-12-20T15:05:49.834469Z",
     "iopub.status.idle": "2023-12-20T15:06:07.386837Z",
     "shell.execute_reply": "2023-12-20T15:06:07.386033Z"
    },
    "papermill": {
     "duration": 17.565442,
     "end_time": "2023-12-20T15:06:07.389271",
     "exception": false,
     "start_time": "2023-12-20T15:05:49.823829",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/kaggle/input/optiver-trading-at-the-close/train.csv\")\n",
    "df = df.dropna(subset=[\"target\"])\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df_shape = df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5bb4f0",
   "metadata": {
    "papermill": {
     "duration": 0.006966,
     "end_time": "2023-12-20T15:06:07.403720",
     "exception": false,
     "start_time": "2023-12-20T15:06:07.396754",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Memory Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbb96b1d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-20T15:06:07.420246Z",
     "iopub.status.busy": "2023-12-20T15:06:07.419647Z",
     "iopub.status.idle": "2023-12-20T15:06:07.533140Z",
     "shell.execute_reply": "2023-12-20T15:06:07.532245Z"
    },
    "papermill": {
     "duration": 0.124222,
     "end_time": "2023-12-20T15:06:07.535184",
     "exception": false,
     "start_time": "2023-12-20T15:06:07.410962",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=0):\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            \n",
    "            if str(col_type)[:3] == \"int\":\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "               \n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "    if verbose:\n",
    "        logger.info(f\"Memory usage of dataframe is {start_mem:.2f} MB\")\n",
    "        end_mem = df.memory_usage().sum() / 1024**2\n",
    "        logger.info(f\"Memory usage after optimization is: {end_mem:.2f} MB\")\n",
    "        decrease = 100 * (start_mem - end_mem) / start_mem\n",
    "        logger.info(f\"Decreased by {decrease:.2f}%\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9cf33f5",
   "metadata": {
    "papermill": {
     "duration": 0.007722,
     "end_time": "2023-12-20T15:06:07.550485",
     "exception": false,
     "start_time": "2023-12-20T15:06:07.542763",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    " # Parallel Triplet Imbalance Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efc2c2d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-20T15:06:07.566171Z",
     "iopub.status.busy": "2023-12-20T15:06:07.565880Z",
     "iopub.status.idle": "2023-12-20T15:06:08.177546Z",
     "shell.execute_reply": "2023-12-20T15:06:08.176582Z"
    },
    "papermill": {
     "duration": 0.621956,
     "end_time": "2023-12-20T15:06:08.179840",
     "exception": false,
     "start_time": "2023-12-20T15:06:07.557884",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from numba import njit, prange\n",
    "\n",
    "@njit(parallel=True)\n",
    "def compute_triplet_imbalance(df_values, comb_indices):\n",
    "    num_rows = df_values.shape[0]\n",
    "    num_combinations = len(comb_indices)\n",
    "    imbalance_features = np.empty((num_rows, num_combinations))\n",
    "    for i in prange(num_combinations):\n",
    "        a, b, c = comb_indices[i]\n",
    "        for j in range(num_rows):\n",
    "            max_val = max(df_values[j, a], df_values[j, b], df_values[j, c])\n",
    "            min_val = min(df_values[j, a], df_values[j, b], df_values[j, c])\n",
    "            mid_val = df_values[j, a] + df_values[j, b] + df_values[j, c] - min_val - max_val\n",
    "            \n",
    "            if mid_val == min_val:\n",
    "                imbalance_features[j, i] = np.nan\n",
    "            else:\n",
    "                imbalance_features[j, i] = (max_val - mid_val) / (mid_val - min_val)\n",
    "\n",
    "    return imbalance_features\n",
    "\n",
    "def calculate_triplet_imbalance_numba(price, df):\n",
    "    df_values = df[price].values\n",
    "    comb_indices = [(price.index(a), price.index(b), price.index(c)) for a, b, c in combinations(price, 3)]\n",
    "    features_array = compute_triplet_imbalance(df_values, comb_indices)\n",
    "    columns = [f\"{a}_{b}_{c}_imb2\" for a, b, c in combinations(price, 3)]\n",
    "    features = pd.DataFrame(features_array, columns=columns)\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e032fac3",
   "metadata": {
    "papermill": {
     "duration": 0.006963,
     "end_time": "2023-12-20T15:06:08.194220",
     "exception": false,
     "start_time": "2023-12-20T15:06:08.187257",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Feature Generation Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01458877",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-20T15:06:08.209532Z",
     "iopub.status.busy": "2023-12-20T15:06:08.209225Z",
     "iopub.status.idle": "2023-12-20T15:06:08.218814Z",
     "shell.execute_reply": "2023-12-20T15:06:08.217959Z"
    },
    "papermill": {
     "duration": 0.019543,
     "end_time": "2023-12-20T15:06:08.220726",
     "exception": false,
     "start_time": "2023-12-20T15:06:08.201183",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@njit(parallel=True)\n",
    "def log_bid_order_flow(df_bid_size, shifted_df_bid_size, df_bid_price, shifted_df_bid_price):\n",
    "    if df_bid_price > shifted_df_bid_price:\n",
    "        return np.log(df_bid_size)\n",
    "\n",
    "    elif df_bid_price == shifted_df_bid_price:\n",
    "        return np.log(df_bid_size) - np.log(shifted_df_bid_size)\n",
    "\n",
    "    else:\n",
    "        return - np.log(shifted_df_bid_size)\n",
    "    \n",
    "@njit(parallel=True)\n",
    "def log_ask_order_flow(df_ask_size, shifted_df_ask_size, df_ask_price, shifted_df_ask_price):\n",
    "    if df_ask_price > shifted_df_ask_price:\n",
    "        return - np.log(shifted_df_ask_size)\n",
    "\n",
    "    elif df_ask_price == shifted_df_ask_price:\n",
    "        return np.log(df_ask_size) - np.log(shifted_df_ask_size)\n",
    "\n",
    "    else:\n",
    "        return np.log(df_ask_size)\n",
    "\n",
    "def calculate_log_bid_order_flow(group):\n",
    "    return group.apply(lambda x: log_bid_order_flow(x[\"bid_size\"], x[\"shifted_bid_size\"], x[\"bid_price\"], x[\"shifted_bid_price\"]), axis=1)\n",
    "\n",
    "def calculate_log_ask_order_flow(group):\n",
    "    return group.apply(lambda x: log_ask_order_flow(x[\"ask_size\"], x[\"shifted_ask_size\"], x[\"ask_price\"], x[\"shifted_ask_price\"]), axis=1)\n",
    "\n",
    "# Define a function to apply EWMA to a specific column with a variable span\n",
    "def apply_ewm(column, span):\n",
    "    return column.ewm(span=span, adjust=False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bfbc5207",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-20T15:06:08.236648Z",
     "iopub.status.busy": "2023-12-20T15:06:08.236397Z",
     "iopub.status.idle": "2023-12-20T15:06:08.239881Z",
     "shell.execute_reply": "2023-12-20T15:06:08.239066Z"
    },
    "papermill": {
     "duration": 0.013005,
     "end_time": "2023-12-20T15:06:08.241610",
     "exception": false,
     "start_time": "2023-12-20T15:06:08.228605",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from tqdm.notebook import tqdm\n",
    "# tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "762f3121",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-20T15:06:08.257155Z",
     "iopub.status.busy": "2023-12-20T15:06:08.256738Z",
     "iopub.status.idle": "2023-12-20T15:06:08.295997Z",
     "shell.execute_reply": "2023-12-20T15:06:08.295268Z"
    },
    "papermill": {
     "duration": 0.049243,
     "end_time": "2023-12-20T15:06:08.297811",
     "exception": false,
     "start_time": "2023-12-20T15:06:08.248568",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def imbalance_features(df):\n",
    "        \n",
    "    df[\"bid_size\"] = df[\"bid_size\"].apply(lambda x: x if x != 0 else 1)\n",
    "    df[\"ask_size\"] = df[\"ask_size\"].apply(lambda x: x if x != 0 else 1)\n",
    "    \n",
    "    # Define lists of price and size-related column names\n",
    "    \n",
    "    prices = [\"reference_price\", \"far_price\", \"near_price\", \"ask_price\", \"bid_price\", \"wap\"]\n",
    "    sizes = [\"matched_size\", \"bid_size\", \"ask_size\", \"imbalance_size\"]\n",
    "    df[\"volume\"] = df.eval(\"ask_size + bid_size\")\n",
    "    df[\"mid_price\"] = df.eval(\"(ask_price + bid_price) / 2\")\n",
    "    df[\"liquidity_imbalance\"] = df.eval(\"(bid_size-ask_size)/(bid_size+ask_size)\")\n",
    "    df[\"matched_imbalance\"] = df.eval(\"(imbalance_size-matched_size)/(matched_size+imbalance_size)\")\n",
    "    df[\"size_imbalance\"] = df.eval(\"bid_size / ask_size\")\n",
    "\n",
    "    for c in combinations(prices, 2):\n",
    "        df[f\"{c[0]}_{c[1]}_imb\"] = df.eval(f\"({c[0]} - {c[1]})/({c[0]} + {c[1]})\")\n",
    "\n",
    "    for c in [['ask_price', 'bid_price', 'wap', 'reference_price'], sizes]:\n",
    "        triplet_feature = calculate_triplet_imbalance_numba(c, df)\n",
    "        df[triplet_feature.columns] = triplet_feature.values\n",
    "   \n",
    "    df[\"imbalance_momentum\"] = df.groupby(['stock_id'])['imbalance_size'].diff(periods=1) / df['matched_size']\n",
    "    df[\"price_spread\"] = df[\"ask_price\"] - df[\"bid_price\"]\n",
    "    df[\"spread_intensity\"] = df.groupby(['stock_id'])['price_spread'].diff()\n",
    "    df['price_pressure'] = df['imbalance_size'] * (df['ask_price'] - df['bid_price'])\n",
    "    df['market_urgency'] = df['price_spread'] * df['liquidity_imbalance']\n",
    "    df['depth_pressure'] = (df['ask_size'] - df['bid_size']) * (df['far_price'] - df['near_price'])\n",
    "    \n",
    "    # Calculate various statistical aggregation features\n",
    "    \n",
    "    for func in [\"mean\", \"std\", \"skew\", \"kurt\"]:\n",
    "        df[f\"all_prices_{func}\"] = df[prices].agg(func, axis=1)\n",
    "        df[f\"all_sizes_{func}\"] = df[sizes].agg(func, axis=1)\n",
    "        \n",
    "\n",
    "    for col in ['matched_size', 'imbalance_size', 'reference_price', 'imbalance_buy_sell_flag']:\n",
    "        for window in [1, 2, 3, 10]:\n",
    "            df[f\"{col}_shift_{window}\"] = df.groupby([\"date_id\", \"stock_id\"], as_index=False)[col].shift(window).reset_index(level=0, drop=True)\n",
    "            df[f\"{col}_ret_{window}\"] = df.groupby([\"date_id\", \"stock_id\"], as_index=False)[col].pct_change(window).reset_index(level=0, drop=True)\n",
    "#             df[f\"{col}_shift_{window}\"] = df.groupby('stock_id')[col].shift(window)\n",
    "#             df[f\"{col}_ret_{window}\"] = df.groupby('stock_id')[col].pct_change(window)\n",
    "        \n",
    "    for window in [1, 2, 3, 10]:\n",
    "            df[f\"market_urgency_shift_{window}\"] = df.groupby([\"date_id\", \"stock_id\"], as_index=False)[\"market_urgency\"].shift(window).reset_index(level=0, drop=True)\n",
    "    \n",
    "    for span in [3,6,9]:\n",
    "            df[f\"ewm_market_urgency_{span}\"] = df.groupby([\"date_id\", \"stock_id\"])[\"market_urgency\"].transform(apply_ewm, span=span)\n",
    "            \n",
    "    # Calculate diff features for specific columns\n",
    "    \n",
    "    for col in ['ask_price', 'bid_price', 'ask_size', 'bid_size', 'market_urgency', 'imbalance_momentum', 'size_imbalance']:\n",
    "        for window in [1, 2, 3, 6]:\n",
    "            df[f\"{col}_diff_{window}\"] = df.groupby([\"date_id\", \"stock_id\"], as_index=False)[col].diff(window).reset_index(level=0, drop=True)\n",
    "    \n",
    "    df = reduce_mem_usage(df)\n",
    "    \n",
    "    # OFI\n",
    "    \n",
    "    df[\"shifted_bid_price\"] = df.groupby([\"date_id\", \"stock_id\"]).bid_price.shift(1).fillna(0)\n",
    "    df[\"shifted_bid_size\"] = df.groupby([\"date_id\", \"stock_id\"]).bid_size.shift(1).fillna(1)\n",
    "\n",
    "    df[\"shifted_ask_price\"] = df.groupby([\"date_id\", \"stock_id\"]).ask_price.shift(1).fillna(10)\n",
    "    df[\"shifted_ask_size\"] = df.groupby([\"date_id\", \"stock_id\"]).ask_size.shift(1).fillna(1)\n",
    "            \n",
    "    df[\"log_bid_orderflow\"] = df.groupby([\"date_id\", \"stock_id\"], as_index=False).apply(calculate_log_bid_order_flow).reset_index(level=0, drop=True)\n",
    "    df[\"log_ask_orderflow\"] = df.groupby([\"date_id\", \"stock_id\"], as_index=False).apply(calculate_log_ask_order_flow).reset_index(level=0, drop=True)\n",
    "    df[\"log_orderflow_imbalance\"] = df.eval(\"log_bid_orderflow - log_ask_orderflow\")\n",
    "    \n",
    "    # Global OFI\n",
    "    df[\"associated_weights\"] = df.stock_id.map(weights)\n",
    "    weights_of_day = dict(df.groupby([\"date_id\", \"seconds_in_bucket\"], group_keys=True)[\"associated_weights\"].sum())\n",
    "    df[\"weighted_log_bid_orderflow\"] = df.eval(\"associated_weights*log_bid_orderflow\")\n",
    "    df[\"weighted_log_ask_orderflow\"] = df.eval(\"associated_weights*log_ask_orderflow\")\n",
    "\n",
    "    w = dict(df.groupby([\"date_id\", \"seconds_in_bucket\"], group_keys=True)[\"weighted_log_bid_orderflow\"].sum())\n",
    "    df[\"global_log_bid_orderflow\"] = pd.Series(list(zip(df.date_id, df.seconds_in_bucket))).map(w)\n",
    "\n",
    "    w = dict(df.groupby([\"date_id\", \"seconds_in_bucket\"], group_keys=True)[\"weighted_log_ask_orderflow\"].sum())\n",
    "    df[\"global_log_ask_orderflow\"] = pd.Series(list(zip(df.date_id, df.seconds_in_bucket))).map(w)\n",
    "\n",
    "    df[\"global_log_bid_orderflow\"] = df[\"global_log_bid_orderflow\"]/pd.Series(list(zip(df.date_id, df.seconds_in_bucket))).map(weights_of_day)\n",
    "    df[\"global_log_ask_orderflow\"] = df[\"global_log_ask_orderflow\"]/pd.Series(list(zip(df.date_id, df.seconds_in_bucket))).map(weights_of_day)\n",
    "    df[\"global_ofi\"] = df.eval(\"global_log_bid_orderflow -  global_log_ask_orderflow\")\n",
    "    df[\"diff_ofi_global_ofi\"] = df.eval(\"log_orderflow_imbalance -  global_ofi\")\n",
    "    \n",
    "    df = reduce_mem_usage(df)\n",
    "    \n",
    "    # index_wap \n",
    "    #df[\"associated_weights\"] = df.stock_id.map(weights)\n",
    "    df.eval(\"weighted_wap = wap*associated_weights\", inplace=True)\n",
    "    w = dict(df.groupby([\"date_id\", \"seconds_in_bucket\"], group_keys=True)[\"weighted_wap\"].sum())\n",
    "    df[\"index_wap\"] = pd.Series(list(zip(df.date_id, df.seconds_in_bucket))).map(w)\n",
    "    #weights_of_day = dict(df.groupby([\"date_id\", \"seconds_in_bucket\"], group_keys=True)[\"associated_weights\"].sum())\n",
    "    df[\"index_wap_norm\"] = df[\"index_wap\"]/pd.Series(list(zip(df.date_id, df.seconds_in_bucket))).map(weights_of_day)\n",
    "    df[\"shift_wap\"] = df.groupby([\"date_id\", \"stock_id\"], as_index=False)[\"wap\"].shift().fillna(1).reset_index(level=0, drop=True)\n",
    "    df[\"shift_index_wap_norm\"] = df.groupby([\"date_id\", \"stock_id\"], as_index=False)[\"index_wap_norm\"].shift().fillna(1).reset_index(level=0, drop=True)\n",
    "    df[\"var_wap\"] = df[\"wap\"]/df[\"shift_wap\"]\n",
    "    df[\"var_index_wap_norm\"] = df[\"index_wap_norm\"]/df[\"shift_index_wap_norm\"]\n",
    "    df.eval(\"diff_var_wap_var_index_wap=var_wap-var_index_wap_norm\", inplace=True)\n",
    "    \n",
    "    del weights_of_day\n",
    "    del w\n",
    "    \n",
    "    # New lag features \n",
    "    \n",
    "    for col in ['log_bid_orderflow', 'log_ask_orderflow', 'log_orderflow_imbalance']:\n",
    "        for window in [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]:\n",
    "            df[f\"{col}_shift_{window}\"] = df.groupby([ \"date_id\", \"stock_id\"], as_index=False)[col].shift(window).reset_index(level=0, drop=True)\n",
    "            \n",
    "    for span in [6, 9]:\n",
    "        df[f\"ewm_diff_var_wap_var_index_wap_{span}\"] = df.groupby([\"date_id\", \"stock_id\"])[\"diff_var_wap_var_index_wap\"].transform(apply_ewm, span=span)\n",
    "    \n",
    "    df.drop(['shifted_bid_price', 'shifted_bid_size', 'shifted_ask_price', 'shifted_ask_size',\n",
    "             'associated_weights', 'index_wap', \"shift_wap\", \"shift_index_wap_norm\"], axis=1, inplace=True)\n",
    "    \n",
    "    df = reduce_mem_usage(df)\n",
    "    \n",
    "    #new features\n",
    "      #diff price features\n",
    "    df[\"diff_ref_price_and_wap\"] = df[\"reference_price\"] - df[\"wap\"]\n",
    "    df[\"diff_near_price_and_far_price\"] = df[\"near_price\"] - df[\"far_price\"]\n",
    "\n",
    "    #imbalance features\n",
    "    df[\"imbalance_1\"] = df[\"imbalance_size\"] * df[\"imbalance_buy_sell_flag\"]\n",
    "    df[\"imbalance_2\"] = df[\"imbalance_size\"] / df[\"matched_size\"]\n",
    "\n",
    "    #volume/size ratio\n",
    "    df[\"ratio_bid_ask\"] = df[\"bid_size\"] / df[\"ask_size\"]\n",
    "    df[\"ratio_size_imbalance_and_bid\"] = df[\"imbalance_size\"] / df[\"bid_size\"]\n",
    "    df[\"ratio_size_imbalance_and_ask\"] = df[\"imbalance_size\"] / df[\"ask_size\"]\n",
    "    df[\"ratio_size_matched_and_askbid\"] = df[\"matched_size\"] / (df[\"bid_size\"] + df[\"ask_size\"])\n",
    "    \n",
    "    #features ratio with shift \n",
    "    for index in [\"ratio_bid_ask\", \"ratio_size_imbalance_and_bid\", \"ratio_size_imbalance_and_ask\", \"ratio_size_matched_and_askbid\", \"imbalance_2\"]:\n",
    "        df[f\"shift_ratio_{index}\"] = df.groupby([\"date_id\", \"stock_id\"], as_index=False)[index].shift().reset_index(level=0, drop=True)\n",
    "        df[f\"ratio_to_ratio_and_shift_ratio_{index}\"] = df[index]/df[f\"shift_ratio_{index}\"]\n",
    "\n",
    "        df.drop([f\"shift_ratio_{index}\"], axis=1, inplace=True)\n",
    "    \n",
    "    return df.replace([np.inf, -np.inf], 0)\n",
    "\n",
    "def other_features(df):\n",
    "    df[\"auction\"] = df[\"seconds_in_bucket\"].apply(lambda x: 1 if x >= 300 else 0)\n",
    "    df[\"dow\"] = df[\"date_id\"] % 5  # Day of the week\n",
    "    df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  \n",
    "    df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  \n",
    "    for key, value in global_stock_id_feats.items():\n",
    "        df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
    "\n",
    "    return df\n",
    "\n",
    "def generate_all_features(df):\n",
    "    # Select relevant columns for feature generation\n",
    "    cols = [c for c in df.columns if c not in [\"row_id\", \"time_id\", \"target\"]]\n",
    "    df = df[cols]\n",
    "    \n",
    "    # Generate imbalance features\n",
    "    df = imbalance_features(df)\n",
    "    df = other_features(df)\n",
    "    gc.collect()  \n",
    "    feature_name = [i for i in df.columns if i not in [\"row_id\", \"target\", \"time_id\", \"date_id\"]]\n",
    "    \n",
    "    return df[feature_name]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "100f507e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-20T15:06:08.313271Z",
     "iopub.status.busy": "2023-12-20T15:06:08.313011Z",
     "iopub.status.idle": "2023-12-20T15:06:08.316791Z",
     "shell.execute_reply": "2023-12-20T15:06:08.315907Z"
    },
    "papermill": {
     "duration": 0.013559,
     "end_time": "2023-12-20T15:06:08.318660",
     "exception": false,
     "start_time": "2023-12-20T15:06:08.305101",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#df = imbalance_features(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac90e8ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-20T15:06:08.334164Z",
     "iopub.status.busy": "2023-12-20T15:06:08.333880Z",
     "iopub.status.idle": "2023-12-20T15:06:08.337659Z",
     "shell.execute_reply": "2023-12-20T15:06:08.336669Z"
    },
    "papermill": {
     "duration": 0.014044,
     "end_time": "2023-12-20T15:06:08.339956",
     "exception": false,
     "start_time": "2023-12-20T15:06:08.325912",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0eeee9a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-20T15:06:08.355357Z",
     "iopub.status.busy": "2023-12-20T15:06:08.355086Z",
     "iopub.status.idle": "2023-12-20T15:06:08.366650Z",
     "shell.execute_reply": "2023-12-20T15:06:08.365838Z"
    },
    "papermill": {
     "duration": 0.021442,
     "end_time": "2023-12-20T15:06:08.368532",
     "exception": false,
     "start_time": "2023-12-20T15:06:08.347090",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "weights = [\n",
    "    0.004, 0.001, 0.002, 0.006, 0.004, 0.004, 0.002, 0.006, 0.006, 0.002, 0.002, 0.008,\n",
    "    0.006, 0.002, 0.008, 0.006, 0.002, 0.006, 0.004, 0.002, 0.004, 0.001, 0.006, 0.004,\n",
    "    0.002, 0.002, 0.004, 0.002, 0.004, 0.004, 0.001, 0.001, 0.002, 0.002, 0.006, 0.004,\n",
    "    0.004, 0.004, 0.006, 0.002, 0.002, 0.04 , 0.002, 0.002, 0.004, 0.04 , 0.002, 0.001,\n",
    "    0.006, 0.004, 0.004, 0.006, 0.001, 0.004, 0.004, 0.002, 0.006, 0.004, 0.006, 0.004,\n",
    "    0.006, 0.004, 0.002, 0.001, 0.002, 0.004, 0.002, 0.008, 0.004, 0.004, 0.002, 0.004,\n",
    "    0.006, 0.002, 0.004, 0.004, 0.002, 0.004, 0.004, 0.004, 0.001, 0.002, 0.002, 0.008,\n",
    "    0.02 , 0.004, 0.006, 0.002, 0.02 , 0.002, 0.002, 0.006, 0.004, 0.002, 0.001, 0.02,\n",
    "    0.006, 0.001, 0.002, 0.004, 0.001, 0.002, 0.006, 0.006, 0.004, 0.006, 0.001, 0.002,\n",
    "    0.004, 0.006, 0.006, 0.001, 0.04 , 0.006, 0.002, 0.004, 0.002, 0.002, 0.006, 0.002,\n",
    "    0.002, 0.004, 0.006, 0.006, 0.002, 0.002, 0.008, 0.006, 0.004, 0.002, 0.006, 0.002,\n",
    "    0.004, 0.006, 0.002, 0.004, 0.001, 0.004, 0.002, 0.004, 0.008, 0.006, 0.008, 0.002,\n",
    "    0.004, 0.002, 0.001, 0.004, 0.004, 0.004, 0.006, 0.008, 0.004, 0.001, 0.001, 0.002,\n",
    "    0.006, 0.004, 0.001, 0.002, 0.006, 0.004, 0.006, 0.008, 0.002, 0.002, 0.004, 0.002,\n",
    "    0.04 , 0.002, 0.002, 0.004, 0.002, 0.002, 0.006, 0.02 , 0.004, 0.002, 0.006, 0.02,\n",
    "    0.001, 0.002, 0.006, 0.004, 0.006, 0.004, 0.004, 0.004, 0.004, 0.002, 0.004, 0.04,\n",
    "    0.002, 0.008, 0.002, 0.004, 0.001, 0.004, 0.006, 0.004,\n",
    "]\n",
    "weights = {int(k):v for k,v in enumerate(weights)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df30fb04",
   "metadata": {
    "papermill": {
     "duration": 0.006791,
     "end_time": "2023-12-20T15:06:08.382504",
     "exception": false,
     "start_time": "2023-12-20T15:06:08.375713",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d4e6ee8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-20T15:06:08.397622Z",
     "iopub.status.busy": "2023-12-20T15:06:08.397343Z",
     "iopub.status.idle": "2023-12-20T15:06:08.402354Z",
     "shell.execute_reply": "2023-12-20T15:06:08.401544Z"
    },
    "papermill": {
     "duration": 0.014859,
     "end_time": "2023-12-20T15:06:08.404388",
     "exception": false,
     "start_time": "2023-12-20T15:06:08.389529",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Online mode\n"
     ]
    }
   ],
   "source": [
    "if is_offline:\n",
    "    \n",
    "    df_train = df[df[\"date_id\"] <= split_day]\n",
    "    df_valid = df[df[\"date_id\"] > split_day]\n",
    "    print(\"Offline mode\")\n",
    "    print(f\"train : {df_train.shape}, valid : {df_valid.shape}\")\n",
    "else:\n",
    "    df_train = df\n",
    "    print(\"Online mode\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98b53e85",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-20T15:06:08.419589Z",
     "iopub.status.busy": "2023-12-20T15:06:08.419314Z",
     "iopub.status.idle": "2023-12-20T15:21:31.482129Z",
     "shell.execute_reply": "2023-12-20T15:21:31.481051Z"
    },
    "papermill": {
     "duration": 923.07305,
     "end_time": "2023-12-20T15:21:31.484522",
     "exception": false,
     "start_time": "2023-12-20T15:06:08.411472",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build Online Train Feats Finished.\n"
     ]
    }
   ],
   "source": [
    "if is_train:\n",
    "    global_stock_id_feats = {\n",
    "        \"median_size\": df_train.groupby(\"stock_id\")[\"bid_size\"].median() + df_train.groupby(\"stock_id\")[\"ask_size\"].median(),\n",
    "        \"std_size\": df_train.groupby(\"stock_id\")[\"bid_size\"].std() + df_train.groupby(\"stock_id\")[\"ask_size\"].std(),\n",
    "        \"ptp_size\": df_train.groupby(\"stock_id\")[\"bid_size\"].max() - df_train.groupby(\"stock_id\")[\"bid_size\"].min(),\n",
    "        \"median_price\": df_train.groupby(\"stock_id\")[\"bid_price\"].median() + df_train.groupby(\"stock_id\")[\"ask_price\"].median(),\n",
    "        \"std_price\": df_train.groupby(\"stock_id\")[\"bid_price\"].std() + df_train.groupby(\"stock_id\")[\"ask_price\"].std(),\n",
    "        \"ptp_price\": df_train.groupby(\"stock_id\")[\"bid_price\"].max() - df_train.groupby(\"stock_id\")[\"ask_price\"].min(),\n",
    "    }\n",
    "    if is_offline:\n",
    "        df_train_feats = generate_all_features(df_train)\n",
    "        print(\"Build Train Feats Finished.\")\n",
    "        df_valid_feats = generate_all_features(df_valid)\n",
    "        print(\"Build Valid Feats Finished.\")\n",
    "        df_valid_feats = reduce_mem_usage(df_valid_feats)\n",
    "    else:\n",
    "        df_train_feats = generate_all_features(df_train)\n",
    "        print(\"Build Online Train Feats Finished.\")\n",
    "\n",
    "    df_train_feats = reduce_mem_usage(df_train_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fbbfc49a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-20T15:21:31.500920Z",
     "iopub.status.busy": "2023-12-20T15:21:31.500575Z",
     "iopub.status.idle": "2023-12-20T15:21:31.504519Z",
     "shell.execute_reply": "2023-12-20T15:21:31.503684Z"
    },
    "papermill": {
     "duration": 0.014117,
     "end_time": "2023-12-20T15:21:31.506441",
     "exception": false,
     "start_time": "2023-12-20T15:21:31.492324",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# a = df_train_feats.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd49e0dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-20T15:21:31.523238Z",
     "iopub.status.busy": "2023-12-20T15:21:31.522646Z",
     "iopub.status.idle": "2023-12-20T19:36:24.787183Z",
     "shell.execute_reply": "2023-12-20T19:36:24.786177Z"
    },
    "papermill": {
     "duration": 15293.315615,
     "end_time": "2023-12-20T19:36:24.829353",
     "exception": false,
     "start_time": "2023-12-20T15:21:31.513738",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature length = 191\n",
      "Fold 1 Model Training\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's l1: 7.08752\n",
      "[200]\tvalid_0's l1: 7.0412\n",
      "[300]\tvalid_0's l1: 7.01438\n",
      "[400]\tvalid_0's l1: 6.99372\n",
      "[500]\tvalid_0's l1: 6.97766\n",
      "[600]\tvalid_0's l1: 6.96398\n",
      "[700]\tvalid_0's l1: 6.95148\n",
      "[800]\tvalid_0's l1: 6.9398\n",
      "[900]\tvalid_0's l1: 6.92935\n",
      "[1000]\tvalid_0's l1: 6.92055\n",
      "[1100]\tvalid_0's l1: 6.91165\n",
      "[1200]\tvalid_0's l1: 6.90303\n",
      "[1300]\tvalid_0's l1: 6.89572\n",
      "[1400]\tvalid_0's l1: 6.88855\n",
      "[1500]\tvalid_0's l1: 6.88191\n",
      "[1600]\tvalid_0's l1: 6.87529\n",
      "[1700]\tvalid_0's l1: 6.86882\n",
      "[1800]\tvalid_0's l1: 6.86275\n",
      "[1900]\tvalid_0's l1: 6.85696\n",
      "[2000]\tvalid_0's l1: 6.85134\n",
      "[2100]\tvalid_0's l1: 6.84541\n",
      "[2200]\tvalid_0's l1: 6.83964\n",
      "[2300]\tvalid_0's l1: 6.83383\n",
      "[2400]\tvalid_0's l1: 6.82824\n",
      "[2500]\tvalid_0's l1: 6.82268\n",
      "[2600]\tvalid_0's l1: 6.8177\n",
      "[2700]\tvalid_0's l1: 6.81216\n",
      "[2800]\tvalid_0's l1: 6.80727\n",
      "[2900]\tvalid_0's l1: 6.80191\n",
      "[3000]\tvalid_0's l1: 6.79829\n",
      "[3100]\tvalid_0's l1: 6.79341\n",
      "[3200]\tvalid_0's l1: 6.78852\n",
      "[3300]\tvalid_0's l1: 6.78369\n",
      "[3400]\tvalid_0's l1: 6.77895\n",
      "[3500]\tvalid_0's l1: 6.77466\n",
      "[3600]\tvalid_0's l1: 6.77036\n",
      "[3700]\tvalid_0's l1: 6.76616\n",
      "[3800]\tvalid_0's l1: 6.76171\n",
      "[3900]\tvalid_0's l1: 6.75756\n",
      "[4000]\tvalid_0's l1: 6.7541\n",
      "[4100]\tvalid_0's l1: 6.75131\n",
      "[4200]\tvalid_0's l1: 6.74894\n",
      "[4300]\tvalid_0's l1: 6.74667\n",
      "[4400]\tvalid_0's l1: 6.74428\n",
      "[4500]\tvalid_0's l1: 6.742\n",
      "[4600]\tvalid_0's l1: 6.73712\n",
      "[4700]\tvalid_0's l1: 6.73478\n",
      "[4800]\tvalid_0's l1: 6.73254\n",
      "[4900]\tvalid_0's l1: 6.73029\n",
      "[5000]\tvalid_0's l1: 6.72808\n",
      "[5100]\tvalid_0's l1: 6.72616\n",
      "[5200]\tvalid_0's l1: 6.72436\n",
      "[5300]\tvalid_0's l1: 6.72249\n",
      "[5400]\tvalid_0's l1: 6.72062\n",
      "[5500]\tvalid_0's l1: 6.71878\n",
      "[5600]\tvalid_0's l1: 6.71692\n",
      "[5700]\tvalid_0's l1: 6.71541\n",
      "[5800]\tvalid_0's l1: 6.71425\n",
      "[5900]\tvalid_0's l1: 6.71299\n",
      "[6000]\tvalid_0's l1: 6.71141\n",
      "[6100]\tvalid_0's l1: 6.7081\n",
      "[6200]\tvalid_0's l1: 6.70635\n",
      "[6300]\tvalid_0's l1: 6.70439\n",
      "[6400]\tvalid_0's l1: 6.70269\n",
      "[6500]\tvalid_0's l1: 6.70119\n",
      "[6600]\tvalid_0's l1: 6.69995\n",
      "[6700]\tvalid_0's l1: 6.69885\n",
      "[6800]\tvalid_0's l1: 6.69762\n",
      "[6900]\tvalid_0's l1: 6.69643\n",
      "[7000]\tvalid_0's l1: 6.69529\n",
      "[7100]\tvalid_0's l1: 6.69418\n",
      "[7200]\tvalid_0's l1: 6.69308\n",
      "[7300]\tvalid_0's l1: 6.692\n",
      "[7400]\tvalid_0's l1: 6.69088\n",
      "[7500]\tvalid_0's l1: 6.68976\n",
      "[7600]\tvalid_0's l1: 6.68876\n",
      "[7700]\tvalid_0's l1: 6.68778\n",
      "[7800]\tvalid_0's l1: 6.68679\n",
      "[7900]\tvalid_0's l1: 6.68581\n",
      "[8000]\tvalid_0's l1: 6.68502\n",
      "[8100]\tvalid_0's l1: 6.68426\n",
      "[8200]\tvalid_0's l1: 6.68334\n",
      "[8300]\tvalid_0's l1: 6.68238\n",
      "[8400]\tvalid_0's l1: 6.68043\n",
      "[8500]\tvalid_0's l1: 6.67919\n",
      "[8600]\tvalid_0's l1: 6.67834\n",
      "[8700]\tvalid_0's l1: 6.67738\n",
      "[8800]\tvalid_0's l1: 6.67632\n",
      "[8900]\tvalid_0's l1: 6.67528\n",
      "[9000]\tvalid_0's l1: 6.67433\n",
      "[9100]\tvalid_0's l1: 6.67336\n",
      "[9200]\tvalid_0's l1: 6.67256\n",
      "[9300]\tvalid_0's l1: 6.67164\n",
      "[9400]\tvalid_0's l1: 6.67078\n",
      "[9500]\tvalid_0's l1: 6.6699\n",
      "[9600]\tvalid_0's l1: 6.66921\n",
      "[9700]\tvalid_0's l1: 6.66851\n",
      "[9800]\tvalid_0's l1: 6.66784\n",
      "[9900]\tvalid_0's l1: 6.66718\n",
      "[10000]\tvalid_0's l1: 6.66655\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 6.66655\n",
      "Model for fold 1 saved to modelitos_para_despues/doblez_1.txt\n",
      "Fold 1 MAE: 6.666551943920505\n",
      "Fold 2 Model Training\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's l1: 6.41868\n",
      "[200]\tvalid_0's l1: 6.38837\n",
      "[300]\tvalid_0's l1: 6.36767\n",
      "[400]\tvalid_0's l1: 6.35181\n",
      "[500]\tvalid_0's l1: 6.33811\n",
      "[600]\tvalid_0's l1: 6.32691\n",
      "[700]\tvalid_0's l1: 6.31706\n",
      "[800]\tvalid_0's l1: 6.30777\n",
      "[900]\tvalid_0's l1: 6.29985\n",
      "[1000]\tvalid_0's l1: 6.29201\n",
      "[1100]\tvalid_0's l1: 6.28566\n",
      "[1200]\tvalid_0's l1: 6.27973\n",
      "[1300]\tvalid_0's l1: 6.27382\n",
      "[1400]\tvalid_0's l1: 6.26844\n",
      "[1500]\tvalid_0's l1: 6.2632\n",
      "[1600]\tvalid_0's l1: 6.2585\n",
      "[1700]\tvalid_0's l1: 6.25358\n",
      "[1800]\tvalid_0's l1: 6.24936\n",
      "[1900]\tvalid_0's l1: 6.24439\n",
      "[2000]\tvalid_0's l1: 6.2396\n",
      "[2100]\tvalid_0's l1: 6.23522\n",
      "[2200]\tvalid_0's l1: 6.23068\n",
      "[2300]\tvalid_0's l1: 6.22659\n",
      "[2400]\tvalid_0's l1: 6.22252\n",
      "[2500]\tvalid_0's l1: 6.21795\n",
      "[2600]\tvalid_0's l1: 6.21359\n",
      "[2700]\tvalid_0's l1: 6.2091\n",
      "[2800]\tvalid_0's l1: 6.20549\n",
      "[2900]\tvalid_0's l1: 6.202\n",
      "[3000]\tvalid_0's l1: 6.19878\n",
      "[3100]\tvalid_0's l1: 6.19536\n",
      "[3200]\tvalid_0's l1: 6.19143\n",
      "[3300]\tvalid_0's l1: 6.18822\n",
      "[3400]\tvalid_0's l1: 6.1847\n",
      "[3500]\tvalid_0's l1: 6.1816\n",
      "[3600]\tvalid_0's l1: 6.17762\n",
      "[3700]\tvalid_0's l1: 6.17418\n",
      "[3800]\tvalid_0's l1: 6.17085\n",
      "[3900]\tvalid_0's l1: 6.16734\n",
      "[4000]\tvalid_0's l1: 6.16428\n",
      "[4100]\tvalid_0's l1: 6.16183\n",
      "[4200]\tvalid_0's l1: 6.15963\n",
      "[4300]\tvalid_0's l1: 6.15608\n",
      "[4400]\tvalid_0's l1: 6.15322\n",
      "[4500]\tvalid_0's l1: 6.15145\n",
      "[4600]\tvalid_0's l1: 6.14977\n",
      "[4700]\tvalid_0's l1: 6.14823\n",
      "[4800]\tvalid_0's l1: 6.14672\n",
      "[4900]\tvalid_0's l1: 6.14556\n",
      "[5000]\tvalid_0's l1: 6.1439\n",
      "[5100]\tvalid_0's l1: 6.14213\n",
      "[5200]\tvalid_0's l1: 6.14049\n",
      "[5300]\tvalid_0's l1: 6.13871\n",
      "[5400]\tvalid_0's l1: 6.13713\n",
      "[5500]\tvalid_0's l1: 6.13553\n",
      "[5600]\tvalid_0's l1: 6.13378\n",
      "[5700]\tvalid_0's l1: 6.13214\n",
      "[5800]\tvalid_0's l1: 6.13092\n",
      "[5900]\tvalid_0's l1: 6.12948\n",
      "[6000]\tvalid_0's l1: 6.12794\n",
      "[6100]\tvalid_0's l1: 6.12585\n",
      "[6200]\tvalid_0's l1: 6.12387\n",
      "[6300]\tvalid_0's l1: 6.12186\n",
      "[6400]\tvalid_0's l1: 6.11995\n",
      "[6500]\tvalid_0's l1: 6.11799\n",
      "[6600]\tvalid_0's l1: 6.11555\n",
      "[6700]\tvalid_0's l1: 6.11384\n",
      "[6800]\tvalid_0's l1: 6.11231\n",
      "[6900]\tvalid_0's l1: 6.11047\n",
      "[7000]\tvalid_0's l1: 6.10736\n",
      "[7100]\tvalid_0's l1: 6.10469\n",
      "[7200]\tvalid_0's l1: 6.10178\n",
      "[7300]\tvalid_0's l1: 6.0988\n",
      "[7400]\tvalid_0's l1: 6.09584\n",
      "[7500]\tvalid_0's l1: 6.09307\n",
      "[7600]\tvalid_0's l1: 6.09017\n",
      "[7700]\tvalid_0's l1: 6.08707\n",
      "[7800]\tvalid_0's l1: 6.08417\n",
      "[7900]\tvalid_0's l1: 6.08166\n",
      "[8000]\tvalid_0's l1: 6.07893\n",
      "[8100]\tvalid_0's l1: 6.07644\n",
      "[8200]\tvalid_0's l1: 6.07426\n",
      "[8300]\tvalid_0's l1: 6.07227\n",
      "[8400]\tvalid_0's l1: 6.07032\n",
      "[8500]\tvalid_0's l1: 6.06833\n",
      "[8600]\tvalid_0's l1: 6.06659\n",
      "[8700]\tvalid_0's l1: 6.0644\n",
      "[8800]\tvalid_0's l1: 6.06214\n",
      "[8900]\tvalid_0's l1: 6.05943\n",
      "[9000]\tvalid_0's l1: 6.05674\n",
      "[9100]\tvalid_0's l1: 6.05464\n",
      "[9200]\tvalid_0's l1: 6.0527\n",
      "[9300]\tvalid_0's l1: 6.05072\n",
      "[9400]\tvalid_0's l1: 6.04911\n",
      "[9500]\tvalid_0's l1: 6.04759\n",
      "[9600]\tvalid_0's l1: 6.0461\n",
      "[9700]\tvalid_0's l1: 6.04412\n",
      "[9800]\tvalid_0's l1: 6.04213\n",
      "[9900]\tvalid_0's l1: 6.04089\n",
      "[10000]\tvalid_0's l1: 6.03953\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 6.03953\n",
      "Model for fold 2 saved to modelitos_para_despues/doblez_2.txt\n",
      "Fold 2 MAE: 6.039527103852166\n",
      "Fold 3 Model Training\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's l1: 6.33185\n",
      "[200]\tvalid_0's l1: 6.29766\n",
      "[300]\tvalid_0's l1: 6.27352\n",
      "[400]\tvalid_0's l1: 6.25538\n",
      "[500]\tvalid_0's l1: 6.23979\n",
      "[600]\tvalid_0's l1: 6.22581\n",
      "[700]\tvalid_0's l1: 6.21419\n",
      "[800]\tvalid_0's l1: 6.2031\n",
      "[900]\tvalid_0's l1: 6.19294\n",
      "[1000]\tvalid_0's l1: 6.18407\n",
      "[1100]\tvalid_0's l1: 6.17617\n",
      "[1200]\tvalid_0's l1: 6.16811\n",
      "[1300]\tvalid_0's l1: 6.16113\n",
      "[1400]\tvalid_0's l1: 6.15449\n",
      "[1500]\tvalid_0's l1: 6.1478\n",
      "[1600]\tvalid_0's l1: 6.14117\n",
      "[1700]\tvalid_0's l1: 6.13399\n",
      "[1800]\tvalid_0's l1: 6.12773\n",
      "[1900]\tvalid_0's l1: 6.12177\n",
      "[2000]\tvalid_0's l1: 6.11572\n",
      "[2100]\tvalid_0's l1: 6.10984\n",
      "[2200]\tvalid_0's l1: 6.10376\n",
      "[2300]\tvalid_0's l1: 6.09792\n",
      "[2400]\tvalid_0's l1: 6.09292\n",
      "[2500]\tvalid_0's l1: 6.08722\n",
      "[2600]\tvalid_0's l1: 6.08134\n",
      "[2700]\tvalid_0's l1: 6.07511\n",
      "[2800]\tvalid_0's l1: 6.06966\n",
      "[2900]\tvalid_0's l1: 6.06525\n",
      "[3000]\tvalid_0's l1: 6.06031\n",
      "[3100]\tvalid_0's l1: 6.05567\n",
      "[3200]\tvalid_0's l1: 6.05049\n",
      "[3300]\tvalid_0's l1: 6.04542\n",
      "[3400]\tvalid_0's l1: 6.04106\n",
      "[3500]\tvalid_0's l1: 6.03677\n",
      "[3600]\tvalid_0's l1: 6.03219\n",
      "[3700]\tvalid_0's l1: 6.02827\n",
      "[3800]\tvalid_0's l1: 6.0248\n",
      "[3900]\tvalid_0's l1: 6.02151\n",
      "[4000]\tvalid_0's l1: 6.01845\n",
      "[4100]\tvalid_0's l1: 6.01568\n",
      "[4200]\tvalid_0's l1: 6.01314\n",
      "[4300]\tvalid_0's l1: 6.01063\n",
      "[4400]\tvalid_0's l1: 6.00813\n",
      "[4500]\tvalid_0's l1: 6.00592\n",
      "[4600]\tvalid_0's l1: 6.00186\n",
      "[4700]\tvalid_0's l1: 5.99861\n",
      "[4800]\tvalid_0's l1: 5.99425\n",
      "[4900]\tvalid_0's l1: 5.99136\n",
      "[5000]\tvalid_0's l1: 5.98746\n",
      "[5100]\tvalid_0's l1: 5.98362\n",
      "[5200]\tvalid_0's l1: 5.98001\n",
      "[5300]\tvalid_0's l1: 5.97668\n",
      "[5400]\tvalid_0's l1: 5.97385\n",
      "[5500]\tvalid_0's l1: 5.97045\n",
      "[5600]\tvalid_0's l1: 5.96757\n",
      "[5700]\tvalid_0's l1: 5.96418\n",
      "[5800]\tvalid_0's l1: 5.96038\n",
      "[5900]\tvalid_0's l1: 5.95699\n",
      "[6000]\tvalid_0's l1: 5.95436\n",
      "[6100]\tvalid_0's l1: 5.95254\n",
      "[6200]\tvalid_0's l1: 5.95116\n",
      "[6300]\tvalid_0's l1: 5.94992\n",
      "[6400]\tvalid_0's l1: 5.94872\n",
      "[6500]\tvalid_0's l1: 5.94756\n",
      "[6600]\tvalid_0's l1: 5.94652\n",
      "[6700]\tvalid_0's l1: 5.94547\n",
      "[6800]\tvalid_0's l1: 5.94446\n",
      "[6900]\tvalid_0's l1: 5.94345\n",
      "[7000]\tvalid_0's l1: 5.94202\n",
      "[7100]\tvalid_0's l1: 5.94099\n",
      "[7200]\tvalid_0's l1: 5.94019\n",
      "[7300]\tvalid_0's l1: 5.93941\n",
      "[7400]\tvalid_0's l1: 5.93861\n",
      "[7500]\tvalid_0's l1: 5.93791\n",
      "[7600]\tvalid_0's l1: 5.93718\n",
      "[7700]\tvalid_0's l1: 5.93568\n",
      "[7800]\tvalid_0's l1: 5.93476\n",
      "[7900]\tvalid_0's l1: 5.93377\n",
      "[8000]\tvalid_0's l1: 5.9328\n",
      "[8100]\tvalid_0's l1: 5.93199\n",
      "[8200]\tvalid_0's l1: 5.9312\n",
      "[8300]\tvalid_0's l1: 5.93046\n",
      "[8400]\tvalid_0's l1: 5.92981\n",
      "[8500]\tvalid_0's l1: 5.92903\n",
      "[8600]\tvalid_0's l1: 5.92838\n",
      "[8700]\tvalid_0's l1: 5.92785\n",
      "[8800]\tvalid_0's l1: 5.92742\n",
      "[8900]\tvalid_0's l1: 5.92695\n",
      "[9000]\tvalid_0's l1: 5.92649\n",
      "[9100]\tvalid_0's l1: 5.92597\n",
      "[9200]\tvalid_0's l1: 5.92517\n",
      "[9300]\tvalid_0's l1: 5.9245\n",
      "[9400]\tvalid_0's l1: 5.92378\n",
      "[9500]\tvalid_0's l1: 5.92322\n",
      "[9600]\tvalid_0's l1: 5.92275\n",
      "[9700]\tvalid_0's l1: 5.92229\n",
      "[9800]\tvalid_0's l1: 5.92188\n",
      "[9900]\tvalid_0's l1: 5.92148\n",
      "[10000]\tvalid_0's l1: 5.92098\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 5.92098\n",
      "Model for fold 3 saved to modelitos_para_despues/doblez_3.txt\n",
      "Fold 3 MAE: 5.920984875897516\n",
      "Fold 4 Model Training\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's l1: 5.97166\n",
      "[200]\tvalid_0's l1: 5.93461\n",
      "[300]\tvalid_0's l1: 5.90739\n",
      "[400]\tvalid_0's l1: 5.8859\n",
      "[500]\tvalid_0's l1: 5.86814\n",
      "[600]\tvalid_0's l1: 5.85147\n",
      "[700]\tvalid_0's l1: 5.83571\n",
      "[800]\tvalid_0's l1: 5.8222\n",
      "[900]\tvalid_0's l1: 5.81043\n",
      "[1000]\tvalid_0's l1: 5.80016\n",
      "[1100]\tvalid_0's l1: 5.78979\n",
      "[1200]\tvalid_0's l1: 5.78089\n",
      "[1300]\tvalid_0's l1: 5.77154\n",
      "[1400]\tvalid_0's l1: 5.7635\n",
      "[1500]\tvalid_0's l1: 5.75496\n",
      "[1600]\tvalid_0's l1: 5.74778\n",
      "[1700]\tvalid_0's l1: 5.74033\n",
      "[1800]\tvalid_0's l1: 5.7323\n",
      "[1900]\tvalid_0's l1: 5.72535\n",
      "[2000]\tvalid_0's l1: 5.71893\n",
      "[2100]\tvalid_0's l1: 5.71252\n",
      "[2200]\tvalid_0's l1: 5.70572\n",
      "[2300]\tvalid_0's l1: 5.69982\n",
      "[2400]\tvalid_0's l1: 5.69315\n",
      "[2500]\tvalid_0's l1: 5.6876\n",
      "[2600]\tvalid_0's l1: 5.6804\n",
      "[2700]\tvalid_0's l1: 5.67451\n",
      "[2800]\tvalid_0's l1: 5.66842\n",
      "[2900]\tvalid_0's l1: 5.66351\n",
      "[3000]\tvalid_0's l1: 5.65978\n",
      "[3100]\tvalid_0's l1: 5.65621\n",
      "[3200]\tvalid_0's l1: 5.65271\n",
      "[3300]\tvalid_0's l1: 5.64979\n",
      "[3400]\tvalid_0's l1: 5.64717\n",
      "[3500]\tvalid_0's l1: 5.64453\n",
      "[3600]\tvalid_0's l1: 5.64234\n",
      "[3700]\tvalid_0's l1: 5.63974\n",
      "[3800]\tvalid_0's l1: 5.63349\n",
      "[3900]\tvalid_0's l1: 5.62859\n",
      "[4000]\tvalid_0's l1: 5.62462\n",
      "[4100]\tvalid_0's l1: 5.6209\n",
      "[4200]\tvalid_0's l1: 5.6174\n",
      "[4300]\tvalid_0's l1: 5.61394\n",
      "[4400]\tvalid_0's l1: 5.60906\n",
      "[4500]\tvalid_0's l1: 5.60441\n",
      "[4600]\tvalid_0's l1: 5.6006\n",
      "[4700]\tvalid_0's l1: 5.59684\n",
      "[4800]\tvalid_0's l1: 5.59333\n",
      "[4900]\tvalid_0's l1: 5.58979\n",
      "[5000]\tvalid_0's l1: 5.5852\n",
      "[5100]\tvalid_0's l1: 5.58002\n",
      "[5200]\tvalid_0's l1: 5.57461\n",
      "[5300]\tvalid_0's l1: 5.56985\n",
      "[5400]\tvalid_0's l1: 5.56464\n",
      "[5500]\tvalid_0's l1: 5.55971\n",
      "[5600]\tvalid_0's l1: 5.55682\n",
      "[5700]\tvalid_0's l1: 5.55358\n",
      "[5800]\tvalid_0's l1: 5.55041\n",
      "[5900]\tvalid_0's l1: 5.54752\n",
      "[6000]\tvalid_0's l1: 5.54468\n",
      "[6100]\tvalid_0's l1: 5.54207\n",
      "[6200]\tvalid_0's l1: 5.54054\n",
      "[6300]\tvalid_0's l1: 5.53903\n",
      "[6400]\tvalid_0's l1: 5.53782\n",
      "[6500]\tvalid_0's l1: 5.53668\n",
      "[6600]\tvalid_0's l1: 5.53559\n",
      "[6700]\tvalid_0's l1: 5.53465\n",
      "[6800]\tvalid_0's l1: 5.53373\n",
      "[6900]\tvalid_0's l1: 5.53293\n",
      "[7000]\tvalid_0's l1: 5.53191\n",
      "[7100]\tvalid_0's l1: 5.53103\n",
      "[7200]\tvalid_0's l1: 5.53016\n",
      "[7300]\tvalid_0's l1: 5.52927\n",
      "[7400]\tvalid_0's l1: 5.52837\n",
      "[7500]\tvalid_0's l1: 5.52755\n",
      "[7600]\tvalid_0's l1: 5.52675\n",
      "[7700]\tvalid_0's l1: 5.526\n",
      "[7800]\tvalid_0's l1: 5.52525\n",
      "[7900]\tvalid_0's l1: 5.52452\n",
      "[8000]\tvalid_0's l1: 5.52386\n",
      "[8100]\tvalid_0's l1: 5.52325\n",
      "[8200]\tvalid_0's l1: 5.52267\n",
      "[8300]\tvalid_0's l1: 5.52213\n",
      "[8400]\tvalid_0's l1: 5.52154\n",
      "[8500]\tvalid_0's l1: 5.52098\n",
      "[8600]\tvalid_0's l1: 5.52035\n",
      "[8700]\tvalid_0's l1: 5.51966\n",
      "[8800]\tvalid_0's l1: 5.51891\n",
      "[8900]\tvalid_0's l1: 5.51803\n",
      "[9000]\tvalid_0's l1: 5.51702\n",
      "[9100]\tvalid_0's l1: 5.51632\n",
      "[9200]\tvalid_0's l1: 5.51565\n",
      "[9300]\tvalid_0's l1: 5.51508\n",
      "[9400]\tvalid_0's l1: 5.51454\n",
      "[9500]\tvalid_0's l1: 5.51401\n",
      "[9600]\tvalid_0's l1: 5.51349\n",
      "[9700]\tvalid_0's l1: 5.51298\n",
      "[9800]\tvalid_0's l1: 5.51247\n",
      "[9900]\tvalid_0's l1: 5.51199\n",
      "[10000]\tvalid_0's l1: 5.51145\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 5.51145\n",
      "Model for fold 4 saved to modelitos_para_despues/doblez_4.txt\n",
      "Fold 4 MAE: 5.511446778972388\n",
      "Fold 5 Model Training\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's l1: 4.83533\n",
      "[200]\tvalid_0's l1: 4.81961\n",
      "[300]\tvalid_0's l1: 4.81385\n",
      "[400]\tvalid_0's l1: 4.81067\n",
      "[500]\tvalid_0's l1: 4.80789\n",
      "[600]\tvalid_0's l1: 4.80578\n",
      "[700]\tvalid_0's l1: 4.80595\n",
      "Early stopping, best iteration is:\n",
      "[636]\tvalid_0's l1: 4.80511\n",
      "Model for fold 5 saved to modelitos_para_despues/doblez_5.txt\n",
      "Fold 5 MAE: 4.805108533790011\n",
      "Training final model with average best iteration: 8127\n",
      "Final model saved to modelitos_para_despues/doblez-conjunto.txt\n",
      "Average MAE across all folds: 5.7887238472865175\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import gc\n",
    "\n",
    "lgb_params = {\n",
    "    \"objective\": \"mae\",\n",
    "    \"n_estimators\": 10000,\n",
    "    \"num_leaves\": 200,\n",
    "    \"subsample\": 0.6,\n",
    "    \"colsample_bytree\": 0.8,\n",
    "#     \"learning_rate\": 0.00871,\n",
    "    \"learning_rate\": 0.01,\n",
    "    'max_depth': 11,\n",
    "    \"n_jobs\": -1,\n",
    "    \"device\": \"gpu\",\n",
    "    \"verbosity\": -1,\n",
    "    \"importance_type\": \"gain\",\n",
    "    \"reg_alpha\": 0.8,\n",
    "    \"reg_lambda\": 3.25\n",
    "}\n",
    "feature_name = list(df_train_feats.columns)\n",
    "print(f\"Feature length = {len(feature_name)}\")\n",
    "\n",
    "num_folds = 5\n",
    "fold_size = 480 // num_folds\n",
    "gap = 10\n",
    "\n",
    "models = []\n",
    "scores = []\n",
    "\n",
    "model_save_path = 'modelitos_para_despues' \n",
    "if not os.path.exists(model_save_path):\n",
    "    os.makedirs(model_save_path)\n",
    "\n",
    "date_ids = df_train['date_id'].values\n",
    "\n",
    "for i in range(num_folds):\n",
    "    start = i * fold_size\n",
    "    end = start + fold_size\n",
    "    if i < num_folds - 1:  # No need to purge after the last fold\n",
    "        purged_start = end - 2\n",
    "        purged_end = end + gap + 2\n",
    "        train_indices = (date_ids >= start) & (date_ids < purged_start) | (date_ids > purged_end)\n",
    "    else:\n",
    "        train_indices = (date_ids >= start) & (date_ids < end)\n",
    "    \n",
    "    test_indices = (date_ids >= end) & (date_ids < end + fold_size)\n",
    "    \n",
    "    df_fold_train = df_train_feats[train_indices]\n",
    "    df_fold_train_target = df_train['target'][train_indices]\n",
    "    df_fold_valid = df_train_feats[test_indices]\n",
    "    df_fold_valid_target = df_train['target'][test_indices]\n",
    "\n",
    "    print(f\"Fold {i+1} Model Training\")\n",
    "    \n",
    "    # Train a LightGBM model for the current fold\n",
    "    lgb_model = lgb.LGBMRegressor(**lgb_params)\n",
    "    lgb_model.fit(\n",
    "        df_fold_train[feature_name],\n",
    "        df_fold_train_target,\n",
    "        eval_set=[(df_fold_valid[feature_name], df_fold_valid_target)],\n",
    "        callbacks=[\n",
    "            lgb.callback.early_stopping(stopping_rounds=100),\n",
    "            lgb.callback.log_evaluation(period=100),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    models.append(lgb_model)\n",
    "    # Save the model to a file\n",
    "    model_filename = os.path.join(model_save_path, f'doblez_{i+1}.txt')\n",
    "    lgb_model.booster_.save_model(model_filename)\n",
    "    print(f\"Model for fold {i+1} saved to {model_filename}\")\n",
    "\n",
    "    # Evaluate model performance on the validation set\n",
    "    fold_predictions = lgb_model.predict(df_fold_valid[feature_name])\n",
    "    fold_score = mean_absolute_error(fold_predictions, df_fold_valid_target)\n",
    "    scores.append(fold_score)\n",
    "    print(f\"Fold {i+1} MAE: {fold_score}\")\n",
    "\n",
    "    # Free up memory by deleting fold specific variables\n",
    "    del df_fold_train, df_fold_train_target, df_fold_valid, df_fold_valid_target\n",
    "    gc.collect()\n",
    "\n",
    "# Calculate the average best iteration from all regular folds\n",
    "average_best_iteration = int(np.mean([model.best_iteration_ for model in models]))\n",
    "\n",
    "# Update the lgb_params with the average best iteration\n",
    "final_model_params = lgb_params.copy()\n",
    "final_model_params['n_estimators'] = average_best_iteration\n",
    "\n",
    "print(f\"Training final model with average best iteration: {average_best_iteration}\")\n",
    "\n",
    "# Train the final model on the entire dataset\n",
    "final_model = lgb.LGBMRegressor(**final_model_params)\n",
    "final_model.fit(\n",
    "    df_train_feats[feature_name],\n",
    "    df_train['target'],\n",
    "    callbacks=[\n",
    "        lgb.callback.log_evaluation(period=100),\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Append the final model to the list of models\n",
    "models.append(final_model)\n",
    "\n",
    "# Save the final model to a file\n",
    "final_model_filename = os.path.join(model_save_path, 'doblez-conjunto.txt')\n",
    "final_model.booster_.save_model(final_model_filename)\n",
    "print(f\"Final model saved to {final_model_filename}\")\n",
    "\n",
    "# Now 'models' holds the trained models for each fold and 'scores' holds the validation scores\n",
    "print(f\"Average MAE across all folds: {np.mean(scores)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551a4240",
   "metadata": {
    "papermill": {
     "duration": 0.040813,
     "end_time": "2023-12-20T19:36:24.910329",
     "exception": false,
     "start_time": "2023-12-20T19:36:24.869516",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f813a31b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-20T19:36:24.992935Z",
     "iopub.status.busy": "2023-12-20T19:36:24.992047Z",
     "iopub.status.idle": "2023-12-20T19:36:25.003575Z",
     "shell.execute_reply": "2023-12-20T19:36:25.002840Z"
    },
    "papermill": {
     "duration": 0.055497,
     "end_time": "2023-12-20T19:36:25.005500",
     "exception": false,
     "start_time": "2023-12-20T19:36:24.950003",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def zero_sum(prices, volumes):\n",
    "    std_error = np.sqrt(volumes)\n",
    "    step = np.sum(prices) / np.sum(std_error)\n",
    "    out = prices - std_error * step\n",
    "    return out\n",
    "\n",
    "if is_infer:\n",
    "    import optiver2023\n",
    "    env = optiver2023.make_env()\n",
    "    iter_test = env.iter_test()\n",
    "    counter = 0\n",
    "    y_min, y_max = -64, 64\n",
    "    qps, predictions = [], []\n",
    "    cache = pd.DataFrame()\n",
    "\n",
    "    # Weights for each fold model\n",
    "    model_weights = [1/len(models)] * len(models) \n",
    "    \n",
    "    for (test, revealed_targets, sample_prediction) in iter_test:\n",
    "        now_time = time.time()\n",
    "        cache = pd.concat([cache, test], ignore_index=True, axis=0)\n",
    "        if counter > 0:\n",
    "            cache = cache.groupby(['stock_id']).tail(21).sort_values(by=['date_id', 'seconds_in_bucket', 'stock_id']).reset_index(drop=True)\n",
    "        feat = generate_all_features(cache)[-len(test):]\n",
    "        feat.drop([\"currently_scored\"], axis=1, inplace=True)\n",
    "        # Generate predictions for each model and calculate the weighted average\n",
    "        lgb_predictions = np.zeros(len(test))\n",
    "        for model, weight in zip(models, model_weights):\n",
    "            lgb_predictions += weight * model.predict(feat)\n",
    "\n",
    "        lgb_predictions = zero_sum(lgb_predictions, test['bid_size'] + test['ask_size'])\n",
    "        clipped_predictions = np.clip(lgb_predictions, y_min, y_max)\n",
    "        sample_prediction['target'] = clipped_predictions\n",
    "        env.predict(sample_prediction)\n",
    "        counter += 1\n",
    "        qps.append(time.time() - now_time)\n",
    "        if counter % 10 == 0:\n",
    "            print(counter, 'qps:', np.mean(qps))\n",
    "\n",
    "    time_cost = 1.146 * np.mean(qps)\n",
    "    print(f\"The code will take approximately {np.round(time_cost, 4)} hours to reason about\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1c6651",
   "metadata": {
    "papermill": {
     "duration": 0.03985,
     "end_time": "2023-12-20T19:36:25.085393",
     "exception": false,
     "start_time": "2023-12-20T19:36:25.045543",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2ed36b",
   "metadata": {
    "papermill": {
     "duration": 0.039545,
     "end_time": "2023-12-20T19:36:25.164677",
     "exception": false,
     "start_time": "2023-12-20T19:36:25.125132",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66f8382",
   "metadata": {
    "papermill": {
     "duration": 0.039825,
     "end_time": "2023-12-20T19:36:25.244497",
     "exception": false,
     "start_time": "2023-12-20T19:36:25.204672",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c3bf22",
   "metadata": {
    "papermill": {
     "duration": 0.040066,
     "end_time": "2023-12-20T19:36:25.324199",
     "exception": false,
     "start_time": "2023-12-20T19:36:25.284133",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ef70fa",
   "metadata": {
    "papermill": {
     "duration": 0.039894,
     "end_time": "2023-12-20T19:36:25.403995",
     "exception": false,
     "start_time": "2023-12-20T19:36:25.364101",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 7056235,
     "sourceId": 57891,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30616,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 16245.646946,
   "end_time": "2023-12-20T19:36:27.301898",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-12-20T15:05:41.654952",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
